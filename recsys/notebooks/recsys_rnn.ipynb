{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import numpy as np\n",
    "import ml_metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs\n",
      "recsys.ipynb\n",
      "recsys_rnn.ipynb\n",
      "test.pkl\n",
      "train.pkl\n",
      "validate.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация session-based подхода\n",
    "\n",
    "По мотивам **Improved Recurrent Neural Networks for Session-based\n",
    "Recommendations** (https://dl.acm.org/doi/pdf/10.1145/2988450.2988452)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала составим словарь фильмов, на которые обратили внимание хотя бы 100 раз. Это намного уменьшит размер модели и, возможно, позволит избежать переобучения. Кроме того, фильмы эти скорее всего не очень крутые, раз у них так мало зрителей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_movies_dict(src, min_bound):\n",
    "    with open(src, 'rb') as file:\n",
    "        users, movies = pickle.load(file)\n",
    "    counter = Counter()\n",
    "    for movies_list in movies:\n",
    "        for movie_id in movies_list:\n",
    "            counter[movie_id] += 1 \n",
    "            \n",
    "    movies_indexes = {'initial': 0}\n",
    "    for movie_id in counter:\n",
    "        if counter[movie_id] >= min_bound:\n",
    "            movies_indexes[movie_id] = len(movies_indexes)\n",
    "    return movies_indexes\n",
    "\n",
    "movies_indexes = create_movies_dict('train.pkl', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_dataset(src, movies_indexes, limit=100):\n",
    "    with open(src, 'rb') as file:\n",
    "        users, user_movies = pickle.load(file)\n",
    "    n_users = len(user_movies)\n",
    "    np_movies = np.zeros((n_users, limit), dtype=np.int)\n",
    "    np_next = np.zeros((n_users, limit), dtype=np.int)\n",
    "    np_lens = np.zeros(n_users, dtype=np.int)\n",
    "    np_users = np.zeros(n_users, dtype=np.int)\n",
    "    \n",
    "    \n",
    "    pointer = 0\n",
    "    for user_id, movies in zip(users, user_movies):\n",
    "        result = np.array([0] + [movies_indexes[movie_id] for movie_id in movies if movie_id in movies_indexes])\n",
    "        if len(result) <= 1:\n",
    "            continue\n",
    "        cur_len = min(len(result) - 1, limit)\n",
    "        np_movies[pointer][0:cur_len] = result[-cur_len - 1: -1]\n",
    "        np_next[pointer][0:cur_len] = result[-cur_len:]\n",
    "        np_lens[pointer] = cur_len\n",
    "        np_users[pointer] = user_id\n",
    "        pointer += 1\n",
    "    return TensorDataset(\n",
    "        torch.LongTensor(np_users[:pointer]), \n",
    "        torch.LongTensor(np_movies[:pointer]), \n",
    "        torch.LongTensor(np_next[:pointer]),\n",
    "        torch.LongTensor(np_lens[:pointer]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationSettings:\n",
    "    def __init__(self, dataset, marked, targets):\n",
    "        self.loader = DataLoader(dataset, batch_size=200, shuffle=False)\n",
    "        self.marked = marked\n",
    "        self.targets = targets\n",
    "        \n",
    "    def evaluate(self, model, N):\n",
    "        expectations, recommendations  = self.get_recommendations(model, N)\n",
    "        return metrics.mapk(expectations, recommendations, k=N)\n",
    "    \n",
    "    def get_recommendations(self, model, N):\n",
    "        recommendations = []\n",
    "        expectations = []\n",
    "        for sample in self.loader:\n",
    "            batch_users, batch_movies, batch_lens = sample\n",
    "            predictions = model.predict_next(batch_movies.to('cuda'), batch_lens.to('cuda'))\n",
    "            predictions = predictions.cpu().detach().numpy()\n",
    "            batch_users = batch_users.cpu().detach().numpy()\n",
    "            for user_id, prediction in zip(batch_users, predictions):\n",
    "                if user_id not in self.marked:\n",
    "                    continue\n",
    "                # Удаляем фильмы, которые были отмечены пользователем в обучающей выборке\n",
    "                prediction[self.marked[user_id]] = -1000000000   \n",
    "                recommendations.append(np.argsort(prediction)[-N:])\n",
    "                expectations.append(self.targets[user_id])\n",
    "        return expectations, recommendations \n",
    "\n",
    "\n",
    "\n",
    "def create_evaluation_settings(train_src, test_src, movies_indexes, limit=100):\n",
    "    with open(train_src, 'rb') as file:\n",
    "        train_users, train_movies = pickle.load(file)\n",
    "    with open(test_src, 'rb') as file:\n",
    "        test_users, test_movies = pickle.load(file)\n",
    "        \n",
    "    n_users = len(test_users)\n",
    "    np_movies = np.zeros((n_users, limit), dtype=np.int)\n",
    "    np_lens = np.zeros(n_users, dtype=np.int)\n",
    "    np_users = np.zeros(n_users, dtype=np.int)\n",
    "    marked = {}\n",
    "    targets = {}\n",
    "    \n",
    "    train_pointer = 0\n",
    "    pointer = 0\n",
    "    for user_id, movies in zip(test_users, test_movies):\n",
    "        while train_users[train_pointer] != user_id:\n",
    "            train_pointer += 1\n",
    "            \n",
    "        result = np.array([0] + [movies_indexes[movie_id] for movie_id in train_movies[train_pointer] \n",
    "                                                                    if movie_id in movies_indexes])\n",
    "        cur_len = min(len(result), limit)\n",
    "        np_movies[pointer][0:cur_len] = result[-cur_len:]\n",
    "        np_lens[pointer] = cur_len\n",
    "        np_users[pointer] = user_id\n",
    "        marked[user_id] = result\n",
    "        targets[user_id] = set([movies_indexes.get(movie_id, -1 - movie_id) for movie_id in movies])\n",
    "        pointer += 1\n",
    "    dataset = TensorDataset(\n",
    "        torch.LongTensor(np_users), \n",
    "        torch.LongTensor(np_movies),\n",
    "        torch.LongTensor(np_lens))\n",
    "    return EvaluationSettings(dataset, marked, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_train_dataset('train.pkl', movies_indexes, limit=150) # ~90% users has less than 150 labels in train set\n",
    "train_loader = DataLoader(train_dataset, batch_size=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_evaluation = create_evaluation_settings('train.pkl', 'validate.pkl', movies_indexes, limit=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionModel(nn.Module):\n",
    "    def __init__(self, num_movies, movie_embedding_dim, hidden_dim):\n",
    "        super(SessionModel, self).__init__()\n",
    "        self.movie_embeddings = nn.Embedding(num_movies, movie_embedding_dim)\n",
    "        # Если верить статье, то GRU справляется с задачей рекоммендации лучше, чем LSTM\n",
    "        # Также утверждается, что дополнительные слои GRU практически не влияют на качество работы\n",
    "        self.rnn = nn.GRU(movie_embedding_dim, hidden_dim)\n",
    "        self.next_film_predictor = nn.Linear(hidden_dim, num_movies)\n",
    "\n",
    "    def forward(self, movies, lens):\n",
    "        vectors = self.movie_embeddings(movies)\n",
    "        packed = pack_padded_sequence(vectors, lens, batch_first=True, enforce_sorted=False)\n",
    "        packed_outputs, _ = self.rnn(packed)\n",
    "        return torch.nn.utils.rnn.PackedSequence(\n",
    "            self.next_film_predictor(packed_outputs.data), \n",
    "            packed_outputs.batch_sizes, \n",
    "            packed_outputs.sorted_indices, \n",
    "            packed_outputs.unsorted_indices)\n",
    "    \n",
    "    def predict_next(self, movies, lens):\n",
    "        vectors = self.movie_embeddings(movies)\n",
    "        packed = pack_padded_sequence(vectors, lens, batch_first=True, enforce_sorted=False)\n",
    "        _, outputs = self.rnn(packed)\n",
    "        return self.next_film_predictor(outputs).view(len(movies), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SessionModel(len(movies_indexes), 128, 128)\n",
    "model.to('cuda')\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch 0\n",
      "Average loss: 0.03550281690410015\n",
      "MAP@20: 0.03909415762871383\n",
      "\n",
      "Start epoch 1\n",
      "Average loss: 0.03238271530431121\n",
      "MAP@20: 0.04560776497896835\n",
      "\n",
      "Start epoch 2\n",
      "Average loss: 0.03144529788450399\n",
      "MAP@20: 0.04958662431351026\n",
      "\n",
      "Start epoch 3\n",
      "Average loss: 0.030913430963537124\n",
      "MAP@20: 0.052219571959024325\n",
      "\n",
      "Start epoch 4\n",
      "Average loss: 0.030627378106659976\n",
      "MAP@20: 0.05351813211290098\n",
      "\n",
      "Start epoch 5\n",
      "Average loss: 0.030461004843230145\n",
      "MAP@20: 0.054065751241001936\n",
      "\n",
      "Start epoch 6\n",
      "Average loss: 0.030356289452404588\n",
      "MAP@20: 0.055035850639178485\n",
      "\n",
      "Start epoch 7\n",
      "Average loss: 0.030280317441114892\n",
      "MAP@20: 0.055206847746913194\n",
      "\n",
      "Start epoch 8\n",
      "Average loss: 0.03022721478518663\n",
      "MAP@20: 0.05530359687697137\n",
      "\n",
      "Start epoch 9\n",
      "Average loss: 0.030179978035994526\n",
      "MAP@20: 0.05524165071744877\n",
      "\n",
      "Start epoch 10\n",
      "Average loss: 0.030147957523121112\n",
      "MAP@20: 0.055521993304684776\n",
      "\n",
      "Start epoch 11\n",
      "Average loss: 0.030113605730087978\n",
      "MAP@20: 0.05597659326784098\n",
      "\n",
      "Start epoch 12\n",
      "Average loss: 0.03008808921268539\n",
      "MAP@20: 0.05614422601378806\n",
      "\n",
      "Start epoch 13\n",
      "Average loss: 0.030059858930350025\n",
      "MAP@20: 0.056368974169184814\n",
      "\n",
      "Start epoch 14\n",
      "Average loss: 0.030047879345789303\n",
      "MAP@20: 0.05629970236448914\n",
      "\n",
      "Start epoch 15\n",
      "Average loss: 0.030024317379615046\n",
      "MAP@20: 0.056076602405292414\n",
      "\n",
      "Start epoch 16\n",
      "Average loss: 0.030007876436898406\n",
      "MAP@20: 0.05615374837788509\n",
      "\n",
      "Start epoch 17\n",
      "Average loss: 0.030011611869594217\n",
      "MAP@20: 0.05666762649485443\n",
      "\n",
      "Start epoch 18\n",
      "Average loss: 0.029975539176713736\n",
      "MAP@20: 0.0565210585225234\n",
      "\n",
      "Start epoch 19\n",
      "Average loss: 0.029962975151265725\n",
      "MAP@20: 0.05653961038353092\n",
      "\n",
      "Start epoch 20\n",
      "Average loss: 0.029960386154908925\n",
      "MAP@20: 0.05683068474720148\n",
      "\n",
      "Start epoch 21\n",
      "Average loss: 0.029947267036912067\n",
      "MAP@20: 0.05678419980750715\n",
      "\n",
      "Start epoch 22\n",
      "Average loss: 0.02993448601740671\n",
      "MAP@20: 0.057026033007174286\n",
      "\n",
      "Start epoch 23\n",
      "Average loss: 0.029926135854790304\n",
      "MAP@20: 0.05733308813414951\n",
      "\n",
      "Start epoch 24\n",
      "Average loss: 0.02991442266712773\n",
      "MAP@20: 0.05723948007087692\n",
      "\n",
      "Start epoch 25\n",
      "Average loss: 0.029905451284323845\n",
      "MAP@20: 0.056977325331058794\n",
      "\n",
      "Start epoch 26\n",
      "Average loss: 0.029897168845257314\n",
      "MAP@20: 0.057086266010175565\n",
      "\n",
      "Start epoch 27\n",
      "Average loss: 0.029885209089307103\n",
      "MAP@20: 0.05747398843676833\n",
      "\n",
      "Start epoch 28\n",
      "Average loss: 0.02988210847431463\n",
      "MAP@20: 0.05675940039172957\n",
      "\n",
      "Start epoch 29\n",
      "Average loss: 0.029873365207074593\n",
      "MAP@20: 0.05695525041117285\n",
      "\n",
      "Start epoch 30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-454d9ba2ddf9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpacked_targets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mloss_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k_epoch in range(1000):\n",
    "    print(\"Start epoch\", k_epoch)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for sample in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        _, batch_movies, batch_targets, batch_lens = sample\n",
    "        packed_pred = model(batch_movies.to('cuda'), batch_lens.to('cuda'))\n",
    "        packed_targets = pack_padded_sequence(batch_targets.to('cuda'), batch_lens.to('cuda'), \n",
    "                                              batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        assert torch.all(packed_pred.batch_sizes == packed_targets.batch_sizes).item()\n",
    "        assert torch.all(packed_pred.unsorted_indices == packed_targets.unsorted_indices).item()\n",
    "        assert torch.all(packed_pred.sorted_indices == packed_targets.sorted_indices).item()\n",
    "            \n",
    "        loss_value = loss(packed_pred.data, packed_targets.data) \n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss_value.item()\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        torch.save(model.state_dict(), os.path.join(\"logs\", \"epoch_\" + str(k_epoch) + \".tmp\"))\n",
    "        print(\"Average loss:\", total_loss / len(train_dataset))\n",
    "        print(\"MAP@20:\", validate_evaluation.evaluate(model, 20))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценим качество на отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(\"logs\", \"epoch_24.tmp\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluation = create_evaluation_settings('train.pkl', 'test.pkl', movies_indexes, limit=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "expectations, recommendations = test_evaluation.get_recommendations(model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(expectations, recommendations, k):\n",
    "    total = 0\n",
    "    for recommendation, expectation in zip(recommendations, expectations):\n",
    "        total += len([x for x in recommendation[:k].tolist() if x in expectation]) / k\n",
    "    return total / len(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>gru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAP@20</td>\n",
       "      <td>0.029890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P@1</td>\n",
       "      <td>0.037141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P@5</td>\n",
       "      <td>0.038634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P@10</td>\n",
       "      <td>0.040309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P@20</td>\n",
       "      <td>0.044984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   metric       gru\n",
       "0  MAP@20  0.029890\n",
       "1     P@1  0.037141\n",
       "2     P@5  0.038634\n",
       "3    P@10  0.040309\n",
       "4    P@20  0.044984"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'metric': ['MAP@20', 'P@1', 'P@5', 'P@10', 'P@20'],\n",
    "             'gru': [\n",
    "                 metrics.mapk(expectations, recommendations, 20),\n",
    "                 precision_at_k(expectations, recommendations, 1),\n",
    "                 precision_at_k(expectations, recommendations, 5),\n",
    "                 precision_at_k(expectations, recommendations, 10),\n",
    "                 precision_at_k(expectations, recommendations, 20),]},\n",
    "             columns=['metric', 'gru'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересно, что так сильно отличается MAP на валидационной выборке и тестовой. Можно было бы списать на переобучение на гиперпараметрах, но валидационная выборка использовалась только для ранней остановки обучения. Видимо так сильно влияет локальность: при разбиении сессий валидационная выборка шла сразу после обучающей. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
